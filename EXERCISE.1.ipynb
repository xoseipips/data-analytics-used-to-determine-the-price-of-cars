{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43a1792",
   "metadata": {},
   "source": [
    "# EXCERCISE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2997d4",
   "metadata": {},
   "source": [
    "## LETS IMPORT NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eaea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f3d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets import the car dataset\n",
    "\n",
    "dataset = pd.read_csv(\"C:\\\\Users/DELL/Desktop/summative_assignment/car_sales_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68331b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(6)  # a view of the first 6 rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ae6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c51568",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum() #......*checking for empty cells*........#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nunique()  #.....*checking for unique variables*.........#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5738fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = dataset.drop_duplicates()  #.....dropping duplicates........#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3220f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.describe()    #.....*some describtive statistics on the dataset*.......#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21d28a",
   "metadata": {},
   "source": [
    "## GOAL (A)\n",
    "Compare regression models that predict the price of a car based on a single \n",
    "numerical input feature. Based on your results, which numerical variable in the \n",
    "dataset is the best predictor for a car’s price, and why? For each numerical input \n",
    "feature, is the price better fit by a linear model or by a non-linear (e.g. polynomial) \n",
    "model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8afad72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of numerical variables\n",
    "numerical_variables = [\"Engine size\", \"Year of manufacture\", \"Mileage\"]\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data_set[numerical_variables]\n",
    "y = data_set[\"Price\"]\n",
    "\n",
    "# Dictionary to store MSE values for each feature and model type\n",
    "mse_results = {}\n",
    "\n",
    "# Function to train and evaluate linear and polynomial regression models\n",
    "def train_and_evaluate_model(feature):\n",
    "    # Linear Regression\n",
    "    model_linear = LinearRegression()\n",
    "    model_linear.fit(X_train[[feature]], y_train)\n",
    "    y_pred_linear = model_linear.predict(X_test[[feature]])\n",
    "    \n",
    "    # Polynomial Regression (degree=2)\n",
    "    model_poly = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "    model_poly.fit(X_train[[feature]], y_train)\n",
    "    y_pred_poly = model_poly.predict(X_test[[feature]])\n",
    "    \n",
    "    # Calculate Mean Squared Error for both models\n",
    "    mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "    mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
    "    \n",
    "    # Store MSE values in the dictionary\n",
    "    mse_results[feature] = {\"Linear\": mse_linear, \"Polynomial\": mse_poly}\n",
    "    \n",
    "    # Visualize the results\n",
    "    plt.scatter(X_test[[feature]], y_test, color='black', label='Actual', s = 5 )\n",
    "    plt.savefig(\"Featu.jpeg\")\n",
    "    plt.plot(X_test[[feature]], y_pred_linear, color='blue', linewidth=1, label='Linear Regression')\n",
    "    plt.plot(X_test[[feature]], y_pred_poly, color='red', linewidth=1, label='Polynomial Regression (degree=2)')\n",
    "    plt.title(f\"{feature} vs Price\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02282e-951b-4511-a072-652776a7168d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train and evaluate models for each numerical variable\n",
    "for feature in numerical_variables:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[[feature]], y, test_size=0.2, random_state=42)\n",
    "    train_and_evaluate_model(feature)\n",
    "\n",
    "# Analyze results and identify the best predictor\n",
    "best_feature = min(mse_results, key=lambda x: mse_results[x][\"Linear\"])\n",
    "print(f\"The best predictor for a car's price is '{best_feature}'.\")\n",
    "\n",
    "# Analyze the best fit model for each numerical feature\n",
    "for feature, mse_dict in mse_results.items():\n",
    "    best_model = min(mse_dict, key=mse_dict.get)\n",
    "    print(f\"For {feature}, the price is better fit by a {best_model} model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de5f31",
   "metadata": {},
   "source": [
    "## GOAL B\n",
    "Consider regression models that take multiple numerical variables as input features \n",
    "to predict the price of a car. Does the inclusion of multiple input features improve \n",
    "the accuracy of the model’s prediction compared to the single-input feature models \n",
    "that you explored in part (a)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc75c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to train and evaluate linear and polynomial regression models\n",
    "def train_and_evaluate_model(features):\n",
    "    # Linear Regression\n",
    "    model_linear = LinearRegression()\n",
    "    model_linear.fit(X_train[features], y_train)\n",
    "    y_pred_linear = model_linear.predict(X_test[features])\n",
    "    \n",
    "    # Polynomial Regression (degree=2)\n",
    "    model_poly = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "    model_poly.fit(X_train[features], y_train)\n",
    "    y_pred_poly = model_poly.predict(X_test[features])\n",
    "    \n",
    "    # Calculate Mean Squared Error for both models\n",
    "    mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "    mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
    "    \n",
    "    return mse_linear, mse_poly\n",
    "\n",
    "# Train and evaluate models for each numerical variable individually\n",
    "mse_results_single = {}\n",
    "for feature in numerical_variables:\n",
    "    mse_linear, mse_poly = train_and_evaluate_model([feature])\n",
    "    mse_results_single[feature] = {\"Linear\": mse_linear, \"Polynomial\": mse_poly}\n",
    "\n",
    "# Train and evaluate models using all numerical variables\n",
    "mse_results_multiple = {}\n",
    "mse_linear, mse_poly = train_and_evaluate_model(numerical_variables)\n",
    "mse_results_multiple[\"All Numerical Variables\"] = {\"Linear\": mse_linear, \"Polynomial\": mse_poly}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c430eec-1eea-4034-a615-1545d3459013",
   "metadata": {},
   "source": [
    "### Compare MSE results for single input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e2256-a34a-4801-b9cf-6a42acb9e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"MSE Results for Single Input Features:\")\n",
    "for feature, mse_dict in mse_results_single.items():\n",
    "    print(f\"{feature}:\")\n",
    "    print(f\"  Linear: {mse_dict['Linear']}\")\n",
    "    print(f\"  Polynomial: {mse_dict['Polynomial']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41078ace-fce6-41b7-b2ce-4ea1fddbe3b9",
   "metadata": {},
   "source": [
    "### Compare MSE results for multiple input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916364c-cbd1-4d70-a2e5-949606949776",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE Results for Multiple Input Features:\")\n",
    "for features, mse_dict in mse_results_multiple.items():\n",
    "    print(f\"{features}:\")\n",
    "    print(f\"  Linear: {mse_dict['Linear']}\")\n",
    "    print(f\"  Polynomial: {mse_dict['Polynomial']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02692e9",
   "metadata": {},
   "source": [
    "## GOAL (C)\n",
    "In parts (a) and (b) you only considered models that use the numerical variables from \n",
    "the dataset as inputs. However, there are also several categorical variables in the\n",
    "dataset that are likely to affect the price of the car. Now train a regression model \n",
    "that uses all relevant input variables (both categorical and numerical) to predict the \n",
    "price (e.g. a Random Forest Regressor model). Does this improve the accuracy of \n",
    "your results? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b683d0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Define features and target variable\n",
    "X = data_set.drop(\"Price\", axis=1)  # Features\n",
    "y = data_set[\"Price\"]  # Target variable\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ed61db-55f4-4343-acd5-a1206f07a16a",
   "metadata": {},
   "source": [
    "### Combine transformers using ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d78796a-257e-41bb-a033-3f7043706155",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs = -1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7300715c-8bf9-486f-9bd1-44c61ada681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f807613",
   "metadata": {},
   "source": [
    "## GOAL (D)\n",
    "Develop an Artificial Neural Network (ANN) model to predict the price of a car based \n",
    "on all the available information from the dataset. How does its performance \n",
    "compare to the other supervised learning models that you have considered? Discuss \n",
    "your choices for the architecture of the neural network that you used, and describe \n",
    "how you tuned the hyperparameters in your model to achieve the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ae4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Drop non-numeric columns and the target variable (price)\n",
    "X = data_set.drop(['Manufacturer', 'Model', 'Fuel type'], axis=1)\n",
    "y = data_set['Price']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06857730-af4d-4331-a746-d3bcb1483c25",
   "metadata": {},
   "source": [
    "### standardise the model data and build neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ef5ed-7397-4733-ae94-0c99ed7d4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Build the neural network model for regression\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Linear activation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1df37a-2e45-4ba7-ba56-22eb0f0d6f9b",
   "metadata": {},
   "source": [
    "### compile, train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019a68dc-67a1-465a-b1fc-492fa1202571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=MeanSquaredError())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "loss = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08332c-bd72-4fb9-b3d6-f088a6c34a66",
   "metadata": {},
   "source": [
    "## comparing with other Supervised learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38752128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assuming 'model' is your trained neural network model\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)   #mean squared error\n",
    "mae = mean_absolute_error(y_val, y_val_pred)  # mean absolute error\n",
    "r2 = r2_score(y_val, y_val_pred)              # r2_score\n",
    "\n",
    "print(f'MSE: {mse}, MAE: {mae}, R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da45f47a-d947-471f-975b-e57bbe353b26",
   "metadata": {},
   "source": [
    "## GOAL E\n",
    "Based on the results of your analysis, what is the best model for predicting the price \n",
    "of a car and why? You should use suitable figures and evaluation metrics to support \n",
    "your conclusions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb1f91-fdc1-4b7b-b846-3446d7290d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#using y_val and y_val_pred as the  actual and predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_val.values.flatten(), y=y_val_pred.flatten(), s = 5)  # to Ensure both are 1-dimensional\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Actual vs. Predicted Prices')\n",
    "plt.savefig(\"Actual vs. Predicted Prices.jpeg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6873f0-a34e-4a50-8c6e-35d637ca1db5",
   "metadata": {},
   "source": [
    "## Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437b7e3-3637-49e2-b54a-29aefb2487b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor  # using scikit-learn for the neural network\n",
    "# X and y are the features and target variable\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 1: Define and Train Neural Network\n",
    "model_nn = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42) \n",
    "model_nn.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Define and Train Linear Regression\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Define and Train Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce5b056-4830-4d3b-a9f5-d151e6dafb9c",
   "metadata": {},
   "source": [
    "### Step 4: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc809c3-0e75-4890-9a9b-cbba89fb6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_nn = model_nn.predict(X_val)\n",
    "y_val_pred_linear = model_linear.predict(X_val)\n",
    "y_val_pred_rf = rf_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ac5b00-3b43-41ca-b980-fca9ce126f59",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be897e43-b4c1-4054-b799-dc7cb8d85075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for neural network\n",
    "mse_nn = mean_squared_error(y_val, y_val_pred_nn)\n",
    "mae_nn = mean_absolute_error(y_val, y_val_pred_nn)\n",
    "r2_nn = r2_score(y_val, y_val_pred_nn)\n",
    "\n",
    "# Calculate metrics for linear regression\n",
    "mse_linear = mean_squared_error(y_val, y_val_pred_linear)\n",
    "mae_linear = mean_absolute_error(y_val, y_val_pred_linear)\n",
    "r2_linear = r2_score(y_val, y_val_pred_linear)\n",
    "\n",
    "# Calculate metrics for random forest\n",
    "mse_rf = mean_squared_error(y_val, y_val_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_val, y_val_pred_rf)\n",
    "r2_rf = r2_score(y_val, y_val_pred_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00bd4ef-12bf-4ed3-aa04-75ef18f454fb",
   "metadata": {},
   "source": [
    "### Step 6: Create the Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8cdca-c6ec-4ade-9261-720abc4647b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Model': ['Neural Network', 'Linear Regression', 'Random Forest'],\n",
    "    'MSE': [mse_nn, mse_linear, mse_rf],\n",
    "    'MAE': [mae_nn, mae_linear, mae_rf],\n",
    "    'R-squared': [r2_nn, r2_linear, r2_rf]\n",
    "}\n",
    "\n",
    "comparison_table = pd.DataFrame(data)\n",
    "\n",
    "print(comparison_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d0686-6aa3-4234-a5de-31f1150f2366",
   "metadata": {},
   "source": [
    "## GOAL F\n",
    "Use the k-Means clustering algorithm to identify clusters in the car sales data. \n",
    "Consider different combinations of the numerical variables in the dataset to use as \n",
    "input features for the clustering algorithm. In each case, what is the optimal number \n",
    "of clusters (k) to use and why? Which combination of variables produces the best \n",
    "clustering results? Use appropriate evaluation metrics to support your conclusions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52231af-372b-4e0d-bf62-11668d8b87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from itertools import combinations\n",
    "\n",
    "# Consider numerical features for clustering same as numerical variable\n",
    "numerical_features = ['Engine size', 'Year of manufacture', 'Mileage', 'Price']\n",
    "\n",
    "# Choose a range of k values for clustering\n",
    "k_range = range(2, 5)\n",
    "\n",
    "# Initialize variables to track the best clustering results\n",
    "best_silhouette_score = -1\n",
    "best_feature_combination = None\n",
    "best_k = None\n",
    "\n",
    "# Iterate over all combinations of features\n",
    "for num_features in range(1, len(numerical_features) + 1):\n",
    "    feature_combinations = combinations(numerical_features, num_features)\n",
    "\n",
    "    for features in feature_combinations:\n",
    "        # Select the subset of features\n",
    "        X_subset = data_set[list(features)]\n",
    "\n",
    "        # Standardize the features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled_subset = scaler.fit_transform(X_subset)\n",
    "\n",
    "        # Experiment with different k values\n",
    "        silhouette_scores = []\n",
    "        for k in k_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            labels = kmeans.fit_predict(X_scaled_subset)\n",
    "            silhouette_avg = silhouette_score(X_scaled_subset, labels)\n",
    "            silhouette_scores.append(silhouette_avg)\n",
    "            print(f\"Silhouette Score for k={k} with features {features}: {silhouette_avg}\")\n",
    "\n",
    "        # Find the index of the maximum silhouette score\n",
    "        optimal_k_index = np.argmax(silhouette_scores)\n",
    "        optimal_silhouette_score = silhouette_scores[optimal_k_index]\n",
    "\n",
    "        # Update best results if the current combination is better\n",
    "        if optimal_silhouette_score > best_silhouette_score:\n",
    "            best_silhouette_score = optimal_silhouette_score\n",
    "            best_feature_combination = features\n",
    "            best_k = k_range[optimal_k_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26d9ac-12cd-425e-9536-8475c4bf1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best combination of variables: {best_feature_combination} with Silhouette Score: {best_silhouette_score}\")\n",
    "print(f\"Optimal number of clusters (k): {best_k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961772d-74bc-4598-a751-86d0de66f186",
   "metadata": {},
   "source": [
    "## GOAL G\n",
    "\n",
    "Compare the results of the k-Means clustering model from part (f) to at least one \n",
    "other clustering algorithm. Which algorithm produces the best clustering? Use \n",
    "suitable evaluation metrics to justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39254b-81c0-41d9-b6d1-bdd77ee4799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming car_data is your DataFrame\n",
    "selected_features = [\"Engine size\", \"Year of manufacture\", \"Mileage\", \"Price\"]\n",
    "\n",
    "# Extract the selected numerical features\n",
    "X_numerical = data_set[selected_features]\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Reduce sample size for clustering\n",
    "sample_size = 500  # Adjust as needed\n",
    "X_scaled_sample = pd.DataFrame(X_scaled).sample(n=sample_size, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d50d4-2ef4-4b03-acb6-b1084fb9a9e8",
   "metadata": {},
   "source": [
    "### Apply k-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297541e0-6b47-40db-b6bd-23fcdbe33d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_k_kmeans = 3  # Adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=chosen_k_kmeans,n_init = \"auto\", random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled_sample)\n",
    "silhouette_kmeans = silhouette_score(X_scaled_sample, kmeans_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f56f8f-6cbe-4978-aa72-7c1f6c34018c",
   "metadata": {},
   "source": [
    "### Apply MiniBatchKMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5cdfa-9e75-4205-9304-e58012c78a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_k_minibatch = 3  # Adjust the number of clusters as needed\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=chosen_k_minibatch,n_init = \"auto\", random_state=42)\n",
    "minibatch_kmeans_labels = minibatch_kmeans.fit_predict(X_scaled_sample)\n",
    "silhouette_minibatch_kmeans = silhouette_score(X_scaled_sample, minibatch_kmeans_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec5892d-6c32-46fb-90b5-fb3de30a8ced",
   "metadata": {},
   "source": [
    "### Visualize the results using PCA (for two principal components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8406fa-1b20-499a-82e8-6d87b5579ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78057da9-fd31-4840-b839-c5b835d7f864",
   "metadata": {},
   "source": [
    "### Scatter plot for k-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56667f83-08d5-4189-bca2-31accffa7b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='viridis', edgecolors='k', s=50)\n",
    "plt.title('k-Means Clustering')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.savefig(\"k-means Clustering.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f085c0-3442-40ec-ae1d-bf9c5fd4dd75",
   "metadata": {},
   "source": [
    "### Scatter plot for MiniBatchKMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ffbb37-3015-499f-b8db-778443050676",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=minibatch_kmeans_labels, cmap='viridis', edgecolors='k', s=50)\n",
    "plt.title('MiniBatchKMeans Clustering')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"minibatch k-means clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7b2eb-bae9-45f4-b3ea-2b99571a060f",
   "metadata": {},
   "source": [
    "### Compare the silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884473f5-4ce9-41cc-bd2c-8ef13448b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Silhouette Score for k-Means Clustering: {silhouette_kmeans}\")\n",
    "print(f\"Silhouette Score for MiniBatchKMeans Clustering: {silhouette_minibatch_kmeans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0837c5-ce0e-4aa6-89c9-2a96a08082cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f3bf8-5249-439a-8e7b-7fe75eb0341d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
