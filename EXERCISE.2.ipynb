{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63765f1-befb-40ad-8a82-96bbac80cb66",
   "metadata": {},
   "source": [
    "## EXERCISE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ccd16-39f1-4832-953a-8b53fd71f13b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path = \"C:/Users/DELL/Desktop/flower_photos\"\n",
    "\n",
    "# Choose a sample image from one class for visualization\n",
    "sample_class = \"Daisy\"\n",
    "sample_image_path = os.path.join(dataset_path, sample_class, os.listdir(os.path.join(dataset_path, sample_class))[0])\n",
    "\n",
    "# Load and display the sample image\n",
    "sample_image = Image.open(sample_image_path)\n",
    "plt.imshow(sample_image)\n",
    "plt.title(f\"Sample Image from {sample_class}\")\n",
    "plt.show()\n",
    "\n",
    "# Set the image size and batch size\n",
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f43d31-b058-4324-9a14-effbdecf724f",
   "metadata": {},
   "source": [
    "### Create an ImageDataGenerator for data augmentation and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75d58e3-f53b-4739-9b4e-505b8f2881c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # If you want to split your dataset into training and validation\n",
    ")\n",
    "\n",
    "# Load the training dataset\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # For multi-class classification\n",
    "    subset='training'  # Use 'validation' for the validation set if you have a split\n",
    ")\n",
    "\n",
    "# Load the validation dataset if split is provided\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e9af8-f93b-4b72-876e-ade17cce53f9",
   "metadata": {},
   "source": [
    "### create CNN model, compile model and display model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47a4d9-6090-4781-ae00-5b0d3559087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d628328-2dd4-45ab-a2bd-251fb228f3ab",
   "metadata": {},
   "source": [
    "### Train the model and store the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb652a4-49a4-48b1-89cb-1e0d939e4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95400eda-5da8-4893-b54c-13d6bedb46d0",
   "metadata": {},
   "source": [
    "### Visualize Training and Validation Accuracy at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752f95b-6342-4d1e-9da9-9473d0e3f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(\"Training and Validation Accuracy.jpeg\", format=\"jpeg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0f57a-41ff-4d1d-9075-9b1ca9acfb56",
   "metadata": {},
   "source": [
    "### Visualize Training and Validation Loss at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234fafff-a6ba-44e0-82bc-be6150421bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"Training and Validation Loss.jpeg\", format=\"jpeg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63158e1e-4a23-4ebd-8941-6ef2637b4d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
